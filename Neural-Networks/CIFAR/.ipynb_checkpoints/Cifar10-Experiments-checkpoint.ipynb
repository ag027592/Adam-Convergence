{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "import keras.backend as K\n",
    "\n",
    "from cifar_model import get_cifar10_cnn\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CIFARNET Convolutional Neural Network Experiments\n",
    "\n",
    "Here, I tune and train CNN models, to recreate the empirical results of section 5 of the paper.\n",
    "\n",
    "As specified in the paper, I fix the parameter $\\beta_1$ at .99, and tune the learning rate $\\alpha$ and the hyperparameter $\\beta_2$ using a gridsearch, as done in the paper. \n",
    "\n",
    "The authors further specified that the number of hidden units is 100, and that they use the Relu activation function. I'll do the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Load CIFAR Dataset\n",
    "\n",
    "I've already created train and test splits for the MNIST dataset. They are conviniently stored as compressed numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load(\"../../data/CIFAR/X_train.npy\")\n",
    "X_test = np.load(\"../../data/CIFAR/X_test.npy\")\n",
    "y_train = np.load(\"../../data/CIFAR/y_train.npy\")\n",
    "y_test = np.load(\"../../data/CIFAR/y_test.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. A framework for exhaustive gridsearch\n",
    "\n",
    "The hyperpameters that I'll need to tune by gridsearch are: \n",
    "\n",
    "- $\\beta_2$\n",
    "- $\\alpha$.\n",
    "\n",
    "To do so in a neat fashion, and make use of all my cores (CPU training :( ) , I'll use the `GridSearchCV` class from `sklearn`, with the `KerasClassifier` wrapper.\n",
    "\n",
    "The interface of this wrapper requres that I define a function that can be called with a set of hyperparameter options and create a `Sequential` model that can be compiled and trained.\n",
    "\n",
    "The function that does this is in the file `cifar_model.py`\n",
    "\n",
    "Note the hyperparameters that I do not tune, as they are fixed by the authors:\n",
    "\n",
    "- $\\beta_1 = .9$\n",
    "- Discount rate: $\\alpha_t$ = $\\frac{\\alpha}{\\sqrt{t}}$\n",
    "- Batch size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 64)        6976      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 16, 16, 64)        147520    \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 16384)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 384)               6291840   \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 192)               73920     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 192)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 192)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                1930      \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 6,522,442\n",
      "Trainable params: 6,522,314\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Example of how this works:\n",
    "get_cifar10_cnn().summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, quicly plotting the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(get_cifar10_cnn(), \"../images/cifarnet_model.png\", show_layer_names=False, show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../images/cifarnet_model.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Reshaping data\n",
    "\n",
    "The input needs to be of dimension (height,width,depth) or (depth, height, width), depeiding on the Keras settings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainlength, testlength = X_train.shape[0], X_test.shape[0]\n",
    "# Reshape the X's, according to our channel setting. \n",
    "if K.image_data_format() == \"channels_last\":\n",
    "    X_train = X_train.reshape(trainlength, 3, 32, 32).transpose(0,2,3,1)\n",
    "    X_test = X_test.reshape((testlength, 3, 32, 32)).transpose(0,2,3,1)\n",
    "else:\n",
    "    X_train = X_train.reshape(trainlength, 3, 32, 32)\n",
    "    X_test = X_test.reshape((testlength, 3, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n",
      "(10000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x124e30f28>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvFvnyVgAAHi1JREFUeJztnX2MnNd13p8z37MfXHK55JIiKS0pUZJdWaZdQlURw3BjJFCMALKBQrALGCpghEEbBTGQohAcIHaB/uEUtQ3/UbigKyFK4dpSYhtWA6OVo9hQ7daKaZumKDO2vvix5HKXy+V+z/ec/jHDgNre5+6SuztL9T4/gODse+a+75k773nfmfvMOcfcHUKI9MhstQNCiK1BwS9Eoij4hUgUBb8QiaLgFyJRFPxCJIqCX4hEUfALkSgKfiESJbeewWb2CIAvA8gC+C/u/vnY8/sH+n3H8I6gLZvj16F8rkCOH7l2xWw9pNVqUZu329wW+eVls9m8aT8yGT4fZsbHZbORvXIf2XsTPVaG2wBus4gtZuotsV/SbpyTkxMTmJudXdMObzn4zSwL4D8B+C0A4wB+YmbPu/sv2ZgdwzvwxL/9w6BtaPsAPdae0X3B7blMHx2Ty3MbIuezR0/om3+T5mbnqK26vExtzVqd2mauXaM2drEZHBykY3L5PLX1b+PvSyty8SqVSsHt+Rw/VqEYvsgD8Qt9LsvHxS56jNiFN3YOmPFxbec3AbbP2EWNjfnXj/9LOmYl67k9PgTgdXd/093rAL4B4NF17E8I0UPWE/z7AFy44e/x7jYhxDuATf9ibGbHzOyEmZ1YWlza7MMJIdbIeoL/IoADN/y9v7vtbbj7cXc/6u5H+wf613E4IcRGsp7g/wmAw2Z20MwKAD4O4PmNcUsIsdnc8mq/uzfN7AkA/xOd9fOn3f3V2JjFpQX8+OUfBG07d26n43btGg1uP3zPA3TM3j13UtvVKb5avri0SG2NRlhiGxoaomP6+/mnnZzxFeD5xVlqu3DhTWpbroQVhPIAX7UfHtlJbbt9hNpiX+OWiZJRLpfpmLGxMWobHNxGbbVqjdrGL4wHtzP/AGDf/v3UVioWqS2mBAwM8vmvVyvB7Zcm/p8P0v9AtRYeU63y17WSden87v5dAN9dzz6EEFvD7fFLGCFEz1HwC5EoCn4hEkXBL0SiKPiFSJR1rfbfLM1mHdMz54O2+aVLdNzVa2Fb2xt0zMzMFWo7d5ZLKFeuTFNbqxWW+g4fvpeOOXjwILVNXOR+TF2epLbz58NzCABLi2GpcvYalw5jST97D3DZqx1JgpqcvBzcPjLCpcOs8WzFgQEu9cXes5M/PxncXq1xeXDHdi47Z3M8ZLYN8nGjo3uordEIy3anX/0FHbNcWQhun5vlMvZKdOcXIlEU/EIkioJfiERR8AuRKAp+IRKlp6v9Zo5MjqyyZvjK/fxieMyvX+dlpCYn+Wr57BWevLO4yBMj2u1wIk4hxxM6ZmemqG3qCrctLoRXcwGguVSltlwzPCejkfJZHknQmR4/S231yK2DJdssFfkp99qvaAU4LBIVAwAuXQorCwCwvBxeSY+V95qe5CpMu80VjmyGlxPr7+eKSp4MuzrDz+FcPuxHq8XjaCW68wuRKAp+IRJFwS9Eoij4hUgUBb8QiaLgFyJReir1tR2oEZWqVuEdalhbq3adJ3Q0lnl9vMU5nkCytBSWhjqOEJkn0pJrJiLnNVtcqlxc4lJfpsmPVyZyUynHOxgVy7y+XN/YIWobvzpBbZVquHZeo84Tai5d5AlLyxU+rlrl584SqdXnkQ46sdZaMYmwVOKSbzvSzWdhMez/ApG4AaA8QGIi0m1oJbrzC5EoCn4hEkXBL0SiKPiFSBQFvxCJouAXIlHWJfWZ2VkACwBaAJrufjT2/HbLsbgYltkKeX4dKuSywe2szREAoMVll/kFLvU5V9+QI/Xb2s73Nz/PfcwYf80RZQjZIs8eyxTC2WNzFd4m69o0n6uxfbyG3+DOcBs1AFiaC7/uytJVOmZxYY7a6nyKsX2Y18fLF8My5vj4OTom9n4WSzw7MhPJqFuKnKv1avjNbrTD5z0A9G2ASL8ROv8/c3cuuAshbkv0sV+IRFlv8DuAF8zsp2Z2bCMcEkL0hvV+7P+Au180s90Avmdmf+/uL934hO5F4RgA5Av8O4wQores687v7he7/08B+DaAhwLPOe7uR939aDav4BfiduGWg9/M+s1s8PpjAL8N4PRGOSaE2FzW87F/FMC3zez6fv6bu/+P2ADLAsWhsKxRjnwlyGfDUlS7wTOzGk1eiDNT5DpaudxPbdls+FqZy3E/2gUuG+Uj09+ocs3RrUhtlXY4e29qgct5lRbP6ls8w4tIHhrjrbd27bwzuH16kst5+RyXMJ27j/k5/l7XSFuudkRGa0f0Xm/z98wiTlaXeQFSIOxLf5n7WMyHfcxE5mkltxz87v4mgPfe6nghxNYiqU+IRFHwC5EoCn4hEkXBL0SiKPiFSJSeFvDMZBzlvrBE4S0u1zhxc2gHl6gaFS6xWZsfq5DnmVn1VnifrUgGYabI5RoDlwgzbb7PxUhx0joxLTa4POjG+8h5nWex7Rji2XQHdg8Ft9crvA+eOy9a2ljg/QRjRTUzWTb/XO5tRQqk1lgFWnBJGgBAitB2PAnbiiW+uzLpeWg3ofXpzi9Eoij4hUgUBb8QiaLgFyJRFPxCJEpvV/sNKJPVyEadr76WMuEV2wzvZoRsg6+uDpL9AUAztppLLpXNWIekDPcjE2nvZJHEk+YCX42em5kPbm9UuJPFEm93NTjMT5Fcnvtx4EBYCbh4bjsds7TEFZq+Pn6fmpjiLdEqlbCyEzkFMFDiCUaNJj/pKhWevJOP1Gtkq/qFPD8/cmR3FlExVqI7vxCJouAXIlEU/EIkioJfiERR8AuRKAp+IRKlp1KfwVDwsMbSJkkzAFAguoxFNLZ2RDbqz/Mkl2KZyzy1VlgSm6/zVkyR/BwgkkCSy3M/+iMto5ZJq6k7RrnENji0k9rmnPs4MfkWtVXrYf1qaAf3Y/wS31+txSW2Nvj8l0hJxnIfz5rJRRJ0qlUuizaXIzJbpN1YnkRhX6SGH2hLMUl9QohVUPALkSgKfiESRcEvRKIo+IVIFAW/EImyqtRnZk8D+F0AU+7+QHfbMIBnAYwBOAvgMXe/ttq+HECDZPUVB7j8VvDwNaoQyVRbnuHSUD3SGuyu/byeXatGMuYict7VCs8SXKrzjD9wpQ/NBT7V5Wr4dRf7+XW+tjBDbRPX+LihnaPUduHi7uD2yzM88226EjmFIvX9hob4ZBXK4TqPtTbX3jLOz53BSCppNaLrzs1FslYRlh2bLT6mUQlLju32xkp9fw7gkRXbngTworsfBvBi928hxDuIVYPf3V8CsPLW8CiAZ7qPnwHw0Q32Swixydzqd/5Rd5/oPr6MTsdeIcQ7iHUv+Lm7I/KbQjM7ZmYnzOxEo8Z/KiqE6C23GvyTZrYXALr/0zpK7n7c3Y+6+9F8pIGFEKK33GrwPw/g8e7jxwF8Z2PcEUL0irVIfV8H8CEAI2Y2DuCzAD4P4Dkz+xSAcwAeW8vB3IF6I/zRvxTLsvJwFltrPtJai0heAJDN8Ky4hWtcbtpGUrP6CvwaauCfdq5dnKa2ZpZLW6UMn6vBTHhO6pXLdMzlyTepbWaJH6uywPf5g4U3gtt3DfO5um83z/hrVLk0l4+061omBTebLX7utMAz90plfu7kWXoegKbzzMNcgbSwi4Rnm2TH3gyrBr+7f4KYPrzuowshtgz9wk+IRFHwC5EoCn4hEkXBL0SiKPiFSJSeFvCEA+16OPPJS9yVFulbVyjyTMDSAJdrqjUuu1y6Gu7tBgDNUvha2bqyRMcMD4ez2wDg7pERapu4cpXaMhFpa3TfruD26Rqfj/LQMLUVr/KsxCvTF6itvbwtuH1gBz/WXaU+asvlw/sDgGyWy14LzbBEOD7PJd3pOpcVvY9UBAUwMMT9j/m4vByWI814lmAxF84+NbtCx6xEd34hEkXBL0SiKPiFSBQFvxCJouAXIlEU/EIkSk+lPm8DrWq47kc9Hyn04WHJo7/Es8Ca7XCxTQCYX+CyV26QF4OcIZll1QWeQdgwXrDywB1cBtx1iEtKZVKUEgDKQ0PB7bNE8gKAnWNj1HbhCpf6/vsLP6C2Rissme4ZvY+O+ccP3k9tV8/+mtratcgc94ezErdHCsaeX+T7aw3yc85yPJzKOS4vDw6EY6JU4O9zqRSW+l4pXKJjVqI7vxCJouAXIlEU/EIkioJfiERR8AuRKD1d7S8Wi7jn4L1BWzbPkxictLVqzXOFoFLhtkadJ1nU23wVOFsKKwEzzleHF+d5olBpgCsS94yGV+0BoFnl4xaqYV/6tvGV4+LSLLXtGeKKxLZBnmzz5uVwfb87Dr+Ljvmdxz5Jbb/+8fep7dRLf01ts1fCq9+DkQSd+/YeoLapBg+ZuTpvlZUv8rlCMXwPNrv52pCGSO+4FejOL0SiKPiFSBQFvxCJouAXIlEU/EIkioJfiERZS7uupwH8LoApd3+gu+1zAH4PwPWCYZ9x9++utq9CvoA79oRllFqVS2LZcli+WKjN8WNFmoJm+/jLzg1xSWyItJPKRGSj2Uu8ptr4FJfsvMWlymKGyzk5C8uio3kuQ01fOkttc1kuYw6UuSy6vBROCPqbH/yIjvnwBz9EbQ8efZja5i/xpJ9TJ8Iy5qVzvNVYcSQi2fVzCTbX5q28mlmeMJbNEqkvJtuF3+abYi13/j8H8Ehg+5fc/Uj336qBL4S4vVg1+N39JQAzPfBFCNFD1vOd/wkzO2VmT5vZjg3zSAjRE241+L8C4G4ARwBMAPgCe6KZHTOzE2Z2gn0PFEL0nlsKfnefdPeWu7cBfBXAQ5HnHnf3o+5+tI9UVRFC9J5bCn4z23vDnx8DcHpj3BFC9Iq1SH1fB/AhACNmNg7gswA+ZGZHADiAswB+fy0Ha7eBaj0sYWWdSyFLc2FJ7NpV3nKpP9I6yYb4sQ7dz2vMDQwQGXDvfjrmHH5FbVfO83ZX569w6XNkB5cW94yEpShetRCYm5mmtukGb0U2NMDr2Q1vC/vx6qlX6Zhnn32O7+9fPEptjYjslc2GP20uLfD5rYHPx1CRy3mlHJeJa9mIbGdhaTEbacvW9vVrfasGv7t/IrD5qXUfWQixpegXfkIkioJfiERR8AuRKAp+IRJFwS9EovS0gGfb26jWwqJTNpLB5Nlwhl6dSCQAUBriBRN37uCZWZVqpPVWvRHcXjQ+jSP776C2dou30Jo8/xa1zczz110ohK/nzSb3MSYpVav8V5kzFZ6xODgQllrn5nkm5o/+10vU1lflxxqOtGabuxqW7WoN/rqay/xc3NnmEtt77j1MbbZ9lNraJIOzWORZk4y/feF/r/m5uvMLkSgKfiESRcEvRKIo+IVIFAW/EImi4BciUXoq9WUzGQz2EfmizeWrHCkUObyDy3kD2wa5IxFp69rVq3wc8TEmUzYjNQzm53h2Xmuc+7hEJEcAmJoJy17VKvejP1KIM6JsYWaaz9XMcniuCqRYJQDMElkOAF57jRfp3FPi584MeT8bkfMtU+XzuzAbyXIs80zS4X17qK3R4MdjuIf9z+d44dqV6M4vRKIo+IVIFAW/EImi4BciURT8QiRKT1f781nDnm03X8G3TZaczfgqe7k/suoZWendtivSjsnDx2u0eYJOI3J5bdf5CvD513liT6vOk48qxJXmfIWOqdZ4azCPTKM3eWXAnIVr3ZX7+Yr4jkgbtTpJCAOA5UKZ2hqlsCJ0bZG3IcvU+PnRuMAVif3jE9S248A+amuR18bOewBwYvM2fy9Xoju/EImi4BciURT8QiSKgl+IRFHwC5EoCn4hEmUt7boOAPgLAKPotOc67u5fNrNhAM8CGEOnZddj7s77ZwEo5HK4czfp5p3hsh2T9DKkth8ANCP18dDiEkoxcj1kCTyRI2EuUivu2gBPqBmMJC3NTc9QW4skfLQaXAIy47Z2xNZq8lc+2BduXVUo8dd8x+gwtfVluB/3vOteamuRJK6Xfvh/6JjKIn/Paku8zdeZV89Q275DXOpj53GbvJcAlwFZPcDgcdfwnCaAP3b3dwN4GMAfmNm7ATwJ4EV3Pwzgxe7fQoh3CKsGv7tPuPvPuo8XAJwBsA/AowCe6T7tGQAf3SwnhRAbz0195zezMQDvA/AygFF3v/6TpsvofC0QQrxDWHPwm9kAgG8C+LS7v61ihHcqCwS/oJjZMTM7YWYn5hf59yUhRG9ZU/CbWR6dwP+au3+ru3nSzPZ27XsBTIXGuvtxdz/q7ke3kUYOQojes2rwW2ep/SkAZ9z9izeYngfwePfx4wC+s/HuCSE2i7Vk9f0GgE8CeMXMTna3fQbA5wE8Z2afAnAOwGOr7skd7UZYHspE6uq1PCxrxOqwRUrFIRdp89WOZAq2jEgykWuotfix9t8RaeH0T95LbT/8Pm/JVJkL15jrL4az7AAgX+SSaS2S1nfv/fupbbkSlstY7TkAmBg/R20PP3SE2t7zvvuozck5MjPFM/DOnH6d2mL1Hy+eP0tti1eDH4wBAAfvPhTc3oxl9ZHzNBc78Vc+d7UnuPsPAVqh8sNrPpIQ4rZCv/ATIlEU/EIkioJfiERR8AuRKAp+IRKlpwU8HVzqaUWykWLyEKPV5DKJRS552TyXxJikF1HzUCzxHzYNDPEMt0Y9Mh/hH1MCAKrVsMRWzvEil9kcf83/6N53Udv9D7yH2k6e/Hlwe63Ki4/OXL1CbSO7R6htYIAXhTXynt13+G465tzrZ6mtssRba83O8qTWt97g8uHYXXcGt5fK/HW1yTlgkezYlejOL0SiKPiFSBQFvxCJouAXIlEU/EIkioJfiETpqdQXIybnZUmBw1ivvlghQyaTAHGJsEkKf9YjWl+1waWhWAZWI1Ics1AoUFs2F56rWLHTUpFLjkPbB/mxsnz+S+XwPoeHSQFXABcuXqA2i7xnRrItAcDJe7Z//x10zM6R7dR2uTZJbYVIduTExGVqm54O9/8b2cOzPpsk05VlMYbQnV+IRFHwC5EoCn4hEkXBL0SiKPiFSJServabGXK58CFjK/dstZ+1LALiK+KWjbzsiB/1JklKqta5H9lI7bwcv/YWCzypY/t2vhrdqoTVhZFtfNV+ZIS3BstEVvQnLl+ktuHhsI8x34tF/r5cmeZJP9UKTxbydlj1KZX5+bFjmM/V/NxVahsc2kVti4uL1PbmW2+Fj7UUrscIAE2Ez/1ajc/FSnTnFyJRFPxCJIqCX4hEUfALkSgKfiESRcEvRKKsKvWZ2QEAf4FOC24HcNzdv2xmnwPwewCuazCfcffvrmF/N+1kkyS5xKS+CqllBwDVOk+2qUVsDXK4VuQamiXSJgBElD7UlyvUFktauuvOu8J+OE8U2jPKE0jujtS6q0SSloaGhoLbY5JXpBMWCgU+j5lMJLGHbM/n+f7GDh6gttlr4SQcABgbi8xVjcvBLCbKfbzuYpHYmJQefO4antME8Mfu/jMzGwTwUzP7Xtf2JXf/j2s+mhDitmEtvfomAEx0Hy+Y2RkA+zbbMSHE5nJT3/nNbAzA+wC83N30hJmdMrOnzYwnagshbjvWHPxmNgDgmwA+7e7zAL4C4G4AR9D5ZPAFMu6YmZ0wsxPzC8sb4LIQYiNYU/CbWR6dwP+au38LANx90t1b7t4G8FUAD4XGuvtxdz/q7ke3DfIGFkKI3rJq8FtnKfIpAGfc/Ys3bN97w9M+BuD0xrsnhNgs1rLa/xsAPgngFTM72d32GQCfMLMj6KgpZwH8/mo7MjPkiRQRk+1YfT+L1P1rkBpnAOBtLlGZc9tgOSyvFIo8Ay8XyS4sFXjG39I8H5fnyhb2H9gT3D5+9g06ptjHT4P9B/ZSW63B5UOq6EYkx5GdPLvwrjv5GnOxxOeqVgtLvq1ITcCR0d3Utm8s3FoLAA4c5LZMJLuz2Qyfc/0D/JMyy1rN3ES7rrWs9v8QQGiPq2r6QojbF/3CT4hEUfALkSgKfiESRcEvRKIo+IVIlB4X8MQtSX0s64kV9gSAfvRzRzKx1k+RFmDEx5i80opk4HlEbtoeaZO1e5QXipycDLeTyhX4XGXzsbZhvCAky7YEgCJpAba0NE/H9PfzLDZWEBTgch7AfWxG3peW8/dz/51j1NYfKZIaO6/cw1JxrB1aux1+XbFzaiW68wuRKAp+IRJFwS9Eoij4hUgUBb8QiaLgFyJReir1ATxD71ay+th2YDVphZpirfrQaoZ9jMlGsYN5rD9hjktzDx45Qm0vvvC3we3mvIDktu28CFOzyV9bvc73yd7Pubk5OmbvXp5BODAwQG2NSCFRJrXGzo9GncubrVYsk5HvMyaLsvM4NvfsUN6W1CeEWAUFvxCJouAXIlEU/EIkioJfiERR8AuRKD2V+tz9lvruMQklJvHENLuYGhKTD1nnt1br5n0HAI9kA84v8Z52A4PhPngA8MB7Hgxuf/nHP6JjLlycoLbhXTupLZPl945KJdxrMCb19fXxgpWx8yMmo9VqYdku9j7PLyxQGyucuZofsfOAZafG9tcmJ7Gy+oQQq6LgFyJRFPxCJIqCX4hEUfALkSirrvabWQnASwCK3ef/lbt/1swOAvgGgJ0Afgrgk+6R7BEAcEeTrNDHVl/z+XCrI4uslseTd/g1rx1J3GjfQgJG7HUtVnntucUqVzKyzseV+sItrwaHePLO6V/+PT9Wjs/VyM5IQhBJqMlk+P5Y3T+A1yYE+PkBgJ4IsaSk2Mr84OCt1unj58GtJB9RH4LNtcKs5c5fA/Cb7v5edNpxP2JmDwP4MwBfcvd7AFwD8Kmb9lQIsWWsGvze4bronO/+cwC/CeCvutufAfDRTfFQCLEprOk7v5llux16pwB8D8AbAGbd/6Hl6jgA3kZVCHHbsabgd/eWux8BsB/AQwDuX+sBzOyYmZ0wsxNzC+FffQkhes9Nrfa7+yyA7wP4pwC2m9n1BcP9AC6SMcfd/ai7Hx0a5E0ZhBC9ZdXgN7NdZra9+7gM4LcAnEHnIvDPu097HMB3NstJIcTGs5bEnr0AnjGzLDoXi+fc/a/N7JcAvmFm/x7AzwE8tdqO2g5UGqQOXiwpoha2NZpcDqvVIrZGpFVTpB5fg8hDVZLEAgCFApeh6i3uYz2SLOSNSNISmd+7D43RMdXqCLXFkqcqJGkGAPr7w+3S7hjiSUmx9mvRxC9qAXJEBuyL1ATMRfyIETt3YhInlfRuoXXczbBq8Lv7KQDvC2x/E53v/0KIdyD6hZ8QiaLgFyJRFPxCJIqCX4hEUfALkSgWr1m3wQczuwLgXPfPEQDTPTs4R368Hfnxdt5pftzl7rvWssOeBv/bDmx2wt2PbsnB5Yf8kB/62C9Eqij4hUiUrQz+41t47BuRH29Hfryd/2/92LLv/EKIrUUf+4VIlC0JfjN7xMx+ZWavm9mTW+FD14+zZvaKmZ00sxM9PO7TZjZlZqdv2DZsZt8zs9e6//PqmJvrx+fM7GJ3Tk6a2Ud64McBM/u+mf3SzF41sz/qbu/pnET86OmcmFnJzP7OzH7R9ePfdbcfNLOXu3HzrJnx3mFrwd17+g9AFp0yYIcAFAD8AsC7e+1H15ezAEa24LgfBPB+AKdv2PYfADzZffwkgD/bIj8+B+Df9Hg+9gJ4f/fxIIBfA3h3r+ck4kdP5wSdLOWB7uM8gJcBPAzgOQAf727/zwD+1XqOsxV3/ocAvO7ub3qn1Pc3ADy6BX5sGe7+EoCZFZsfRacQKtCjgqjEj57j7hPu/rPu4wV0isXsQ4/nJOJHT/EOm140dyuCfx+ACzf8vZXFPx3AC2b2UzM7tkU+XGfU3a+3y70MYHQLfXnCzE51vxZs+tePGzGzMXTqR7yMLZyTFX4APZ6TXhTNTX3B7wPu/n4AvwPgD8zsg1vtENC58oP1A998vgLgbnR6NEwA+EKvDmxmAwC+CeDT7j5/o62XcxLwo+dz4usomrtWtiL4LwI4cMPftPjnZuPuF7v/TwH4Nra2MtGkme0FgO7/U1vhhLtPdk+8NoCvokdzYmZ5dALua+7+re7mns9JyI+tmpPusW+6aO5a2Yrg/wmAw92VywKAjwN4vtdOmFm/mQ1efwzgtwGcjo/aVJ5HpxAqsIUFUa8HW5ePoQdzYp0idk8BOOPuX7zB1NM5YX70ek56VjS3VyuYK1YzP4LOSuobAP5ki3w4hI7S8AsAr/bSDwBfR+fjYwOd726fQqfn4YsAXgPwNwCGt8iP/wrgFQCn0Am+vT3w4wPofKQ/BeBk999Hej0nET96OicAHkSnKO4pdC40f3rDOft3AF4H8JcAius5jn7hJ0SipL7gJ0SyKPiFSBQFvxCJouAXIlEU/EIkioJfiERR8AuRKAp+IRLl/wKMU4LDBh38mgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[551])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Set up gridsearches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Make a hyperparemter grid to search through\n",
    "\"\"\"\n",
    "beta2_range = np.append(np.arange(.990, .999, .0025), .999)\n",
    "alpha_range = [.0001*10**i for i in range(5)]\n",
    "param_grid = dict(lr=alpha_range, beta_2=beta2_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'beta_2': array([0.99  , 0.9925, 0.995 , 0.9975, 0.999 ]),\n",
       " 'lr': [0.0001, 0.001, 0.01, 0.1, 1.0]}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 25 candidates, totalling 75 fits\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-57-3e7bceec9fae>\", line 3, in <module>\n",
      "    adam_grid_result = adam_grid.fit(X_train, y_train)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/sklearn/model_selection/_search.py\", line 639, in fit\n",
      "    cv.split(X, y, groups)))\n",
      "  File \"/usr/local/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 779, in __call__\n",
      "    while self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 625, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 588, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\", line 111, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\", line 332, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 131, in __call__\n",
      "    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n",
      "  File \"/usr/local/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 131, in <listcomp>\n",
      "    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n",
      "  File \"/usr/local/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\", line 458, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/keras/wrappers/scikit_learn.py\", line 209, in fit\n",
      "    return super(KerasClassifier, self).fit(x, y, **kwargs)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/keras/wrappers/scikit_learn.py\", line 151, in fit\n",
      "    history = self.model.fit(x, y, **fit_args)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/keras/models.py\", line 963, in fit\n",
      "    validation_steps=validation_steps)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/keras/engine/training.py\", line 1705, in fit\n",
      "    validation_steps=validation_steps)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/keras/engine/training.py\", line 1235, in _fit_loop\n",
      "    outs = f(ins_batch)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\", line 2478, in __call__\n",
      "    **self.session_kwargs)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 905, in run\n",
      "    run_metadata_ptr)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1137, in _run\n",
      "    feed_dict_tensor, options, run_metadata)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1355, in _do_run\n",
      "    options, run_metadata)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1361, in _do_call\n",
      "    return fn(*args)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1340, in _run_fn\n",
      "    target_list, status, run_metadata)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 1828, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1090, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 311, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 345, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/usr/local/Cellar/python/3.6.4_4/Frameworks/Python.framework/Versions/3.6/lib/python3.6/inspect.py\", line 1483, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/usr/local/Cellar/python/3.6.4_4/Frameworks/Python.framework/Versions/3.6/lib/python3.6/inspect.py\", line 1441, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/usr/local/Cellar/python/3.6.4_4/Frameworks/Python.framework/Versions/3.6/lib/python3.6/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/usr/local/Cellar/python/3.6.4_4/Frameworks/Python.framework/Versions/3.6/lib/python3.6/inspect.py\", line 725, in getmodule\n",
      "    file = getabsfile(object, _filename)\n",
      "  File \"/usr/local/Cellar/python/3.6.4_4/Frameworks/Python.framework/Versions/3.6/lib/python3.6/inspect.py\", line 709, in getabsfile\n",
      "    return os.path.normcase(os.path.abspath(_filename))\n",
      "  File \"/usr/local/Cellar/python/3.6.4_4/Frameworks/Python.framework/Versions/3.6/lib/python3.6/posixpath.py\", line 374, in abspath\n",
      "    cwd = os.getcwd()\n",
      "FileNotFoundError: [Errno 2] No such file or directory\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "adam_model = KerasClassifier(build_fn=get_cifar10_cnn, epochs=50, batch_size=128, verbose=2)\n",
    "adam_grid = GridSearchCV(estimator=adam_model, param_grid=param_grid, n_jobs=1, verbose=1)\n",
    "adam_grid_result = adam_grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 25 candidates, totalling 75 fits\n",
      "Epoch 1/50\n",
      "Epoch 1/50\n",
      "Epoch 1/50\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-58-01bdeb76b132>\", line 9, in <module>\n",
      "    ams_grid_result = ams_grid.fit(X_train, y_train)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/sklearn/model_selection/_search.py\", line 639, in fit\n",
      "    cv.split(X, y, groups)))\n",
      "  File \"/usr/local/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 789, in __call__\n",
      "    self.retrieve()\n",
      "  File \"/usr/local/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 699, in retrieve\n",
      "    self._output.extend(job.get(timeout=self.timeout))\n",
      "  File \"/usr/local/Cellar/python/3.6.4_4/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/pool.py\", line 638, in get\n",
      "    self.wait(timeout)\n",
      "  File \"/usr/local/Cellar/python/3.6.4_4/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/pool.py\", line 635, in wait\n",
      "    self._event.wait(timeout)\n",
      "  File \"/usr/local/Cellar/python/3.6.4_4/Frameworks/Python.framework/Versions/3.6/lib/python3.6/threading.py\", line 551, in wait\n",
      "    signaled = self._cond.wait(timeout)\n",
      "  File \"/usr/local/Cellar/python/3.6.4_4/Frameworks/Python.framework/Versions/3.6/lib/python3.6/threading.py\", line 295, in wait\n",
      "    waiter.acquire()\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 1828, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1090, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 311, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 345, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/usr/local/Cellar/python/3.6.4_4/Frameworks/Python.framework/Versions/3.6/lib/python3.6/inspect.py\", line 1483, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/usr/local/Cellar/python/3.6.4_4/Frameworks/Python.framework/Versions/3.6/lib/python3.6/inspect.py\", line 1441, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/usr/local/Cellar/python/3.6.4_4/Frameworks/Python.framework/Versions/3.6/lib/python3.6/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/usr/local/Cellar/python/3.6.4_4/Frameworks/Python.framework/Versions/3.6/lib/python3.6/inspect.py\", line 725, in getmodule\n",
      "    file = getabsfile(object, _filename)\n",
      "  File \"/usr/local/Cellar/python/3.6.4_4/Frameworks/Python.framework/Versions/3.6/lib/python3.6/inspect.py\", line 709, in getabsfile\n",
      "    return os.path.normcase(os.path.abspath(_filename))\n",
      "  File \"/usr/local/Cellar/python/3.6.4_4/Frameworks/Python.framework/Versions/3.6/lib/python3.6/posixpath.py\", line 374, in abspath\n",
      "    cwd = os.getcwd()\n",
      "FileNotFoundError: [Errno 2] No such file or directory\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Gridsearch through learning rate and beta_2 combinations, using the AMSGrad optimizer\n",
    "\"\"\"\n",
    "# Same grid, but now using AMS optimizer\n",
    "param_grid_ams = dict(lr=alpha_range, beta_2=beta2_range, amsgrad = [True])\n",
    "\n",
    "ams_model = KerasClassifier(build_fn=get_cifar10_cnn, epochs=50, batch_size=128, verbose=2)\n",
    "ams_grid = GridSearchCV(estimator=ams_model, param_grid=param_grid_ams, n_jobs=-1, verbose = 1)\n",
    "ams_grid_result = ams_grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
